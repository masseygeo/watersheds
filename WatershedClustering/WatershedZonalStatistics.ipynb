{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bb37d65-1890-419a-825f-f6074de27c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from WatershedClustering_Utils import zonal_statistics_to_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55b31d0-6817-42ca-a070-ae2d1e0d8408",
   "metadata": {},
   "source": [
    "# Aggregated Terrain Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32b71026-f9af-46ba-92f3-39cb98f573d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to polygon shapefile defining zones to calculate aggregated statistics\n",
    "watersheds_path = '../Datasets/nhd/ky_huc10_26916.shp'\n",
    "\n",
    "# path to dem\n",
    "dem_path = r'../Datasets/dem_10m/dem_clipped_26916.tif'\n",
    "\n",
    "# path to terrain features derived from dem (as glob object)\n",
    "terrain_feature_paths = glob.glob('../Datasets/terrain_features/*.tif')\n",
    "\n",
    "# append dem path for complete list of features\n",
    "terrain_feature_paths.append(dem_path)\n",
    "\n",
    "# normalize paths for consistency\n",
    "terrain_feature_paths = [os.path.normpath(path) for path in terrain_feature_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8b9052a-eab1-41de-b227-a2fddf34fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through terrain features and calculate zonal statistics...\n",
    "# for tf in terrain_feature_paths:\n",
    "for tf in ['..\\\\Datasets\\\\terrain_features\\\\aspect_26916.tif']:\n",
    "\n",
    "    # define statistics to calculate (built in to rasterstats)\n",
    "    statistics = ['sum', 'majority', 'range', 'mean', 'std', 'min', 'percentile_10', 'percentile_25', 'median', 'percentile_75', 'percentile_90', 'max']\n",
    "\n",
    "    # label for saving zonal statistics .csv file\n",
    "    label = os.path.splitext(os.path.basename(tf))[0]\n",
    "\n",
    "    # call custom function \n",
    "    zonal_statistics_to_csv(watersheds_path, tf, statistics, f\"{label}_huc10_zonalstats.csv\", index_col='huc10', drop_cols=['loaddate', 'name', 'geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8fb31b-f62e-4fd5-9e7c-474ae970cfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Terrain Features #####\n",
    "# aspect - \n",
    "# flow accumulation - \n",
    "# flow drop - \n",
    "# profile curvature - \n",
    "# roughness index - \n",
    "# slope - \n",
    "# stream power index (spi) - \n",
    "# standard deviation of elevation - \n",
    "# tangential curvature - \n",
    "# topographic wetness index (twi) - \n",
    "#\n",
    "# * manually deleted sum from aspect because it doesn't provide useful information\n",
    "# ** some stats provide redundant information, so may need to manually remove (feature selection) or use dimensionality reduction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
